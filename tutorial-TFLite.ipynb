{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "727c782c-c8b2-45eb-a2fb-6294ae0084e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# Import tensorflow model optimization, used for quantization-aware training\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09dd2c55-149a-4ce6-872b-e2be84a28f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove annoying logging\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fcb427-33d4-4b73-945c-f988bb0716fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e46f449-2949-4a30-9178-8658d92bd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "# Basic standardization\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b09a67-33ca-43be-9c95-13a7569f404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 15:50:44.216600: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-08 15:50:46.824403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11423 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:85:00.0, compute capability: 6.1\n",
      "2022-02-08 15:50:46.825199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 11423 MB memory:  -> device: 1, name: NVIDIA TITAN Xp, pci bus id: 0000:89:00.0, compute capability: 6.1\n",
      "2022-02-08 15:50:46.825841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11433 MB memory:  -> device: 2, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:05:00.0, compute capability: 6.1\n",
      "2022-02-08 15:50:46.826447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 11433 MB memory:  -> device: 3, name: NVIDIA TITAN X (Pascal), pci bus id: 0000:09:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# Basic neural network deifnition\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc380f7-a9cd-4515-a838-d5b550096b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 15:50:48.221405: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n",
      "2022-02-08 15:50:48.703499: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 9s 4ms/step - loss: 0.2522 - accuracy: 0.9287 - val_loss: 0.0941 - val_accuracy: 0.9750\n",
      "Epoch 2/2\n",
      "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0905 - accuracy: 0.9739 - val_loss: 0.0673 - val_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c54521a90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=2,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e42e2e-b8db-428e-893d-6141d3ed589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0693 - accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06934657692909241, 0.9789000153541565]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the original model\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e2a1a2-cb0e-460b-ab4d-9bfd22419910",
   "metadata": {},
   "source": [
    "# Quantization-aware finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369a8555-af38-472c-aaa4-b8770843b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( Optional) Clone model\n",
    "model_q = tf.keras.models.clone_model(model)\n",
    "model_q.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e20c65d-88e2-49b7-95d2-a4ceeae83af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quantization-aware model\n",
    "model_q = tfmot.quantization.keras.quantize_model(model_q)\n",
    "\n",
    "model_q.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2212cff7-0a20-4fa5-9fde-5ba3259a46e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 4.0795 - accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.079493999481201, 0.11349999904632568]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the quantized model WITHOUT retraining\n",
    "model_q.evaluate(x_test,y_test)\n",
    "# accuracy should be pretty low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3adbdf4d-1d29-46ed-8017-0569a02d2674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 12s 7ms/step - loss: 0.0670 - accuracy: 0.9801 - val_loss: 0.0601 - val_accuracy: 0.9833\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0551 - val_accuracy: 0.9852\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 11s 7ms/step - loss: 0.0454 - accuracy: 0.9856 - val_loss: 0.0585 - val_accuracy: 0.9828\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058014679700136185, 0.9817000031471252]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrain the model with quantization-aware training\n",
    "model_q.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=3,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "# evaluate model AFTER retraining\n",
    "model_q.evaluate(x_test,y_test)\n",
    "# accuracy should be equivalent to the accuracy before quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f3dda-82ca-4d0c-8246-6aaf1324f584",
   "metadata": {},
   "source": [
    "# TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5d3dc5-03de-43cd-b22b-bbddc17a942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that converts a tensorflow model to a tensorflow lite model\n",
    "def convert_TF_to_TFLite(model_tf, X_train, TFLite_target_filename):\n",
    "    # Create TFLite model from the original TF model\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model_tf)\n",
    "    # Set the optimization flag to use default quantization\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    # Enforce integer only quantization\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    # Also Quantize input and output (not mandatory, replace with tf.float32 to keep floating representations)\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    # Provide a representative dataset to optimize quantization with respect to expected data distribution\n",
    "    def generate_representative_dataset():\n",
    "        for i in range(len(X_train)//10):\n",
    "            yield([np.float32(X_train[i]).reshape(1, X_train[0].size)])\n",
    "    # Converter will use the above function to optimize quantization\n",
    "    converter.representative_dataset = generate_representative_dataset\n",
    "    #convert to TFLite\n",
    "    model_tflite = converter.convert()\n",
    "    open(TFLite_target_filename, \"wb\").write(model_tflite)\n",
    "    # If you want to read the on-disk size (good proxy for on device size)\n",
    "    # size = os.path.getsize(TFLite_target_filename)\n",
    "    return model_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e2e718-66b9-4512-8c5d-020ed515da03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 15:51:44.682716: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as reshape_layer_call_fn, reshape_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, flatten_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_jvv02nm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_jvv02nm/assets\n",
      "/home/vpo/envs/tf2/lib/python3.8/site-packages/tensorflow/lite/python/convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n",
      "2022-02-08 15:51:46.098049: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-02-08 15:51:46.098084: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-02-08 15:51:46.099064: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp_jvv02nm\n",
      "2022-02-08 15:51:46.102142: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-02-08 15:51:46.102162: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmp_jvv02nm\n",
      "2022-02-08 15:51:46.114338: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-02-08 15:51:46.173914: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp_jvv02nm\n",
      "2022-02-08 15:51:46.195365: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 96304 microseconds.\n",
      "2022-02-08 15:51:46.228268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "fully_quantize: 0WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      ", inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    }
   ],
   "source": [
    "# convert our TF model to TFLite\n",
    "model_tflite = convert_TF_to_TFLite(model_q, x_train, \"model.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da7d3bce-612a-47a2-a377-e2a967ce8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the TFLite model on disk: 58.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the size\n",
    "size = os.path.getsize(\"model.tflite\")\n",
    "print(f\"Size of the TFLite model on disk: {size/1000} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4668b1df-e4e6-4f3f-95d5-0a43f38a3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the inference on data x_test with a TFLite model\n",
    "def predict_TFLite(model, X, num_classes=10):\n",
    "    x_data = np.copy(X) # the function quantizes the input, so we must make a copy\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "    # Inputs will be quantized\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    if (input_scale, input_zero_point) != (0.0, 0):\n",
    "        x_data = x_data / input_scale + input_zero_point\n",
    "        x_data = x_data.astype(input_details[\"dtype\"])\n",
    "    # Invoke the interpreter\n",
    "    predictions = np.empty((x_data.shape[0],num_classes), dtype=output_details[\"dtype\"])\n",
    "    for i in range(len(x_data)):\n",
    "        interpreter.set_tensor(input_details[\"index\"], [x_data[i]])\n",
    "        interpreter.invoke()\n",
    "        predictions[i] = np.copy(interpreter.get_tensor(output_details[\"index\"])[0])\n",
    "    # Dequantize output\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    if (output_scale, output_zero_point) != (0.0, 0):\n",
    "        predictions = predictions.astype(np.float32)\n",
    "        predictions = (predictions - output_zero_point) * output_scale\n",
    "    # todo reshape output into array for each exit\n",
    "    return predictions\n",
    "\n",
    "def evaluate_TFLite(model, X, Y):\n",
    "    time_start = time.time()\n",
    "    predictions = predict_TFLite(model, X)\n",
    "    predictions = np.argmax(predictions,axis=-1)\n",
    "    accuracy = np.nanmean(predictions.flatten()==Y.flatten())*100\n",
    "    time_end = time.time()\n",
    "    print(f\"Ellapsed time: {time_end-time_start:.3f} s for {predictions.shape[0]} samples\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd807116-8233-4b01-82b6-1e34b60ebaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ellapsed time: 8.063 s for 10000 samples\n",
      "Accuracy of the TFLite model: 98.17%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the TFLite model on the test images\n",
    "accuracy = evaluate_TFLite(model_tflite, x_test, y_test)\n",
    "print(f\"Accuracy of the TFLite model: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae779ac-bf5b-4951-ade2-2d4167524ba4",
   "metadata": {},
   "source": [
    "# TensorFlow Lite for Microcontrollers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1736a4b4-dc8d-4b18-b9cf-02e40a3c65c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a C++ array of the TFLite model\n",
    "# The model needs to be saved on disk\n",
    "def convert_TFLite_to_TFLM(TFLite_filename, TFLM_target_filename):\n",
    "    # Read a TFLite saved model, convert it to TFLite Micro\n",
    "    # Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "    !xxd -i {TFLite_filename} > {TFLM_target_filename}\n",
    "    # Update variable names\n",
    "    REPLACE_TEXT = TFLite_filename.replace('/', '_').replace('.', '_')\n",
    "    !sed -i 's/'{REPLACE_TEXT}'/g_model/g' {TFLM_target_filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0dd0435-9d8a-40bd-8801-87916d48e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model on disk\n",
    "open(\"model.tflite\", \"wb\").write(model_tflite)\n",
    "# Convert to TFLM\n",
    "convert_TFLite_to_TFLM(\"model.tflite\", \"embedded_model.cc\")\n",
    "# It takes a few second to obtain the file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
